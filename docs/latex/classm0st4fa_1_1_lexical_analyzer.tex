\hypertarget{classm0st4fa_1_1_lexical_analyzer}{}\doxysection{m0st4fa\+::Lexical\+Analyzer\texorpdfstring{$<$}{<} TokenT, TableT, InputT \texorpdfstring{$>$}{>} Class Template Reference}
\label{classm0st4fa_1_1_lexical_analyzer}\index{m0st4fa::LexicalAnalyzer$<$ TokenT, TableT, InputT $>$@{m0st4fa::LexicalAnalyzer$<$ TokenT, TableT, InputT $>$}}


{\ttfamily \#include $<$Lexical\+Analyzer.\+h$>$}

\doxysubsection*{Public Member Functions}
\begin{DoxyCompactItemize}
\item 
\mbox{\hyperlink{classm0st4fa_1_1_lexical_analyzer_ac9780af3718c7ca8c9e266c18068a195}{Lexical\+Analyzer}} ()=default
\item 
\mbox{\hyperlink{classm0st4fa_1_1_lexical_analyzer_a2ca5caacf72c67a63e15711536f15599}{Lexical\+Analyzer}} (const DFAType$<$ Trans\+Fn$<$ TableT $>$, InputT $>$ \&automaton, const \mbox{\hyperlink{namespacem0st4fa_a58965446aff3084930498d9cce4e9997}{Token\+Factory\+Type}}$<$ TokenT, InputT $>$ token\+Factory, const std\+::string\+\_\+view source\+Code)
\item 
\mbox{\hyperlink{classm0st4fa_1_1_lexical_analyzer_aedfbc5995c40ab51b5240cc28504df42}{Lexical\+Analyzer}} (const \mbox{\hyperlink{classm0st4fa_1_1_lexical_analyzer}{Lexical\+Analyzer}} \&)=default
\item 
\mbox{\hyperlink{classm0st4fa_1_1_lexical_analyzer_a7b1474f2eae431d8161fc8c926464bf1}{Lexical\+Analyzer}} (\mbox{\hyperlink{classm0st4fa_1_1_lexical_analyzer}{Lexical\+Analyzer}} \&\&)=default
\item 
\mbox{\hyperlink{classm0st4fa_1_1_lexical_analyzer}{Lexical\+Analyzer}} \& \mbox{\hyperlink{classm0st4fa_1_1_lexical_analyzer_abcbf6d3869e434c507198d397dbf0afa}{operator=}} (const \mbox{\hyperlink{classm0st4fa_1_1_lexical_analyzer}{Lexical\+Analyzer}} \&rhs)
\item 
\mbox{\hyperlink{structm0st4fa_1_1_lexical_analyzer_result}{Result}} \mbox{\hyperlink{classm0st4fa_1_1_lexical_analyzer_a360582fb5a0a0c77553dfdfcba14fcbc}{get\+Next\+Token}} (unsigned=(unsigned) \mbox{\hyperlink{namespacem0st4fa_a650a9bd65d2a3b704ebe88b2cedf33e9ab8f839029805bbb167407d29588a2df9}{LA\+\_\+\+FLAG\+::\+LAF\+\_\+\+DEFAULT}})
\begin{DoxyCompactList}\small\item\em get the next matching token from the input, skipping all nonmatching characters in between this and the previous match. \end{DoxyCompactList}\item 
const std\+::string\+\_\+view \& \mbox{\hyperlink{classm0st4fa_1_1_lexical_analyzer_ab0311f5dc70584a1c72b5ef08e60c434}{get\+Source\+Code}} ()
\item 
\mbox{\hyperlink{structm0st4fa_1_1_lexical_analyzer_result}{Result}} \mbox{\hyperlink{classm0st4fa_1_1_lexical_analyzer_a649be99fb43c662f84fd9e2578e08b62}{peak}} (unsigned=(unsigned) \mbox{\hyperlink{namespacem0st4fa_a650a9bd65d2a3b704ebe88b2cedf33e9ab8f839029805bbb167407d29588a2df9}{LA\+\_\+\+FLAG\+::\+LAF\+\_\+\+DEFAULT}})
\begin{DoxyCompactList}\small\item\em peak the next token without modifying character count nor line number, except that it deals with whitespace as normal (i.\+e. may skip them, depending on the flags, and hence modify line number and character count). \end{DoxyCompactList}\item 
size\+\_\+t \mbox{\hyperlink{classm0st4fa_1_1_lexical_analyzer_a2102c8791bfff625f6dd1e1a041c58b5}{get\+Line}} ()
\item 
size\+\_\+t \mbox{\hyperlink{classm0st4fa_1_1_lexical_analyzer_adee6ddc157dcbcfdc0969b8c59d2e1c0}{get\+Col}} ()
\item 
\mbox{\hyperlink{structm0st4fa_1_1_position}{Position}} \mbox{\hyperlink{classm0st4fa_1_1_lexical_analyzer_a8fe9088959a4edcd58bd500267221cb0}{get\+Position}} ()
\end{DoxyCompactItemize}
\doxysubsection*{Protected Member Functions}
\begin{DoxyCompactItemize}
\item 
const DFAType$<$ Trans\+Fn$<$ TableT $>$, InputT $>$ \& \mbox{\hyperlink{classm0st4fa_1_1_lexical_analyzer_a78175d1ee2447dca701e2eeaae3fe518}{get\+Automatan}} ()
\item 
const \mbox{\hyperlink{namespacem0st4fa_a58965446aff3084930498d9cce4e9997}{Token\+Factory\+Type}}$<$ TokenT, InputT $>$ \mbox{\hyperlink{classm0st4fa_1_1_lexical_analyzer_a104e6bb82d82935f490ec847e47d32b9}{get\+Token\+Factory}} ()
\end{DoxyCompactItemize}


\doxysubsection{Constructor \& Destructor Documentation}
\Hypertarget{classm0st4fa_1_1_lexical_analyzer_ac9780af3718c7ca8c9e266c18068a195}\label{classm0st4fa_1_1_lexical_analyzer_ac9780af3718c7ca8c9e266c18068a195} 
\index{m0st4fa::LexicalAnalyzer$<$ TokenT, TableT, InputT $>$@{m0st4fa::LexicalAnalyzer$<$ TokenT, TableT, InputT $>$}!LexicalAnalyzer@{LexicalAnalyzer}}
\index{LexicalAnalyzer@{LexicalAnalyzer}!m0st4fa::LexicalAnalyzer$<$ TokenT, TableT, InputT $>$@{m0st4fa::LexicalAnalyzer$<$ TokenT, TableT, InputT $>$}}
\doxysubsubsection{\texorpdfstring{LexicalAnalyzer()}{LexicalAnalyzer()}\hspace{0.1cm}{\footnotesize\ttfamily [1/4]}}
{\footnotesize\ttfamily template$<$typename TokenT , typename TableT  = FSMTable, typename InputT  = std\+::string\+\_\+view$>$ \\
\mbox{\hyperlink{classm0st4fa_1_1_lexical_analyzer}{m0st4fa\+::\+Lexical\+Analyzer}}$<$ TokenT, TableT, InputT $>$\+::\+Lexical\+Analyzer (\begin{DoxyParamCaption}{ }\end{DoxyParamCaption})\hspace{0.3cm}{\ttfamily [default]}}

\Hypertarget{classm0st4fa_1_1_lexical_analyzer_a2ca5caacf72c67a63e15711536f15599}\label{classm0st4fa_1_1_lexical_analyzer_a2ca5caacf72c67a63e15711536f15599} 
\index{m0st4fa::LexicalAnalyzer$<$ TokenT, TableT, InputT $>$@{m0st4fa::LexicalAnalyzer$<$ TokenT, TableT, InputT $>$}!LexicalAnalyzer@{LexicalAnalyzer}}
\index{LexicalAnalyzer@{LexicalAnalyzer}!m0st4fa::LexicalAnalyzer$<$ TokenT, TableT, InputT $>$@{m0st4fa::LexicalAnalyzer$<$ TokenT, TableT, InputT $>$}}
\doxysubsubsection{\texorpdfstring{LexicalAnalyzer()}{LexicalAnalyzer()}\hspace{0.1cm}{\footnotesize\ttfamily [2/4]}}
{\footnotesize\ttfamily template$<$typename TokenT , typename TableT  = FSMTable, typename InputT  = std\+::string\+\_\+view$>$ \\
\mbox{\hyperlink{classm0st4fa_1_1_lexical_analyzer}{m0st4fa\+::\+Lexical\+Analyzer}}$<$ TokenT, TableT, InputT $>$\+::\+Lexical\+Analyzer (\begin{DoxyParamCaption}\item[{const DFAType$<$ Trans\+Fn$<$ TableT $>$, InputT $>$ \&}]{automaton,  }\item[{const \mbox{\hyperlink{namespacem0st4fa_a58965446aff3084930498d9cce4e9997}{Token\+Factory\+Type}}$<$ TokenT, InputT $>$}]{token\+Factory,  }\item[{const std\+::string\+\_\+view}]{source\+Code }\end{DoxyParamCaption})\hspace{0.3cm}{\ttfamily [inline]}}

\Hypertarget{classm0st4fa_1_1_lexical_analyzer_aedfbc5995c40ab51b5240cc28504df42}\label{classm0st4fa_1_1_lexical_analyzer_aedfbc5995c40ab51b5240cc28504df42} 
\index{m0st4fa::LexicalAnalyzer$<$ TokenT, TableT, InputT $>$@{m0st4fa::LexicalAnalyzer$<$ TokenT, TableT, InputT $>$}!LexicalAnalyzer@{LexicalAnalyzer}}
\index{LexicalAnalyzer@{LexicalAnalyzer}!m0st4fa::LexicalAnalyzer$<$ TokenT, TableT, InputT $>$@{m0st4fa::LexicalAnalyzer$<$ TokenT, TableT, InputT $>$}}
\doxysubsubsection{\texorpdfstring{LexicalAnalyzer()}{LexicalAnalyzer()}\hspace{0.1cm}{\footnotesize\ttfamily [3/4]}}
{\footnotesize\ttfamily template$<$typename TokenT , typename TableT  = FSMTable, typename InputT  = std\+::string\+\_\+view$>$ \\
\mbox{\hyperlink{classm0st4fa_1_1_lexical_analyzer}{m0st4fa\+::\+Lexical\+Analyzer}}$<$ TokenT, TableT, InputT $>$\+::\+Lexical\+Analyzer (\begin{DoxyParamCaption}\item[{const \mbox{\hyperlink{classm0st4fa_1_1_lexical_analyzer}{Lexical\+Analyzer}}$<$ TokenT, TableT, InputT $>$ \&}]{ }\end{DoxyParamCaption})\hspace{0.3cm}{\ttfamily [default]}}

\Hypertarget{classm0st4fa_1_1_lexical_analyzer_a7b1474f2eae431d8161fc8c926464bf1}\label{classm0st4fa_1_1_lexical_analyzer_a7b1474f2eae431d8161fc8c926464bf1} 
\index{m0st4fa::LexicalAnalyzer$<$ TokenT, TableT, InputT $>$@{m0st4fa::LexicalAnalyzer$<$ TokenT, TableT, InputT $>$}!LexicalAnalyzer@{LexicalAnalyzer}}
\index{LexicalAnalyzer@{LexicalAnalyzer}!m0st4fa::LexicalAnalyzer$<$ TokenT, TableT, InputT $>$@{m0st4fa::LexicalAnalyzer$<$ TokenT, TableT, InputT $>$}}
\doxysubsubsection{\texorpdfstring{LexicalAnalyzer()}{LexicalAnalyzer()}\hspace{0.1cm}{\footnotesize\ttfamily [4/4]}}
{\footnotesize\ttfamily template$<$typename TokenT , typename TableT  = FSMTable, typename InputT  = std\+::string\+\_\+view$>$ \\
\mbox{\hyperlink{classm0st4fa_1_1_lexical_analyzer}{m0st4fa\+::\+Lexical\+Analyzer}}$<$ TokenT, TableT, InputT $>$\+::\+Lexical\+Analyzer (\begin{DoxyParamCaption}\item[{\mbox{\hyperlink{classm0st4fa_1_1_lexical_analyzer}{Lexical\+Analyzer}}$<$ TokenT, TableT, InputT $>$ \&\&}]{ }\end{DoxyParamCaption})\hspace{0.3cm}{\ttfamily [default]}}



\doxysubsection{Member Function Documentation}
\Hypertarget{classm0st4fa_1_1_lexical_analyzer_a78175d1ee2447dca701e2eeaae3fe518}\label{classm0st4fa_1_1_lexical_analyzer_a78175d1ee2447dca701e2eeaae3fe518} 
\index{m0st4fa::LexicalAnalyzer$<$ TokenT, TableT, InputT $>$@{m0st4fa::LexicalAnalyzer$<$ TokenT, TableT, InputT $>$}!getAutomatan@{getAutomatan}}
\index{getAutomatan@{getAutomatan}!m0st4fa::LexicalAnalyzer$<$ TokenT, TableT, InputT $>$@{m0st4fa::LexicalAnalyzer$<$ TokenT, TableT, InputT $>$}}
\doxysubsubsection{\texorpdfstring{getAutomatan()}{getAutomatan()}}
{\footnotesize\ttfamily template$<$typename TokenT , typename TableT  = FSMTable, typename InputT  = std\+::string\+\_\+view$>$ \\
const DFAType$<$ Trans\+Fn$<$ TableT $>$, InputT $>$ \& \mbox{\hyperlink{classm0st4fa_1_1_lexical_analyzer}{m0st4fa\+::\+Lexical\+Analyzer}}$<$ TokenT, TableT, InputT $>$\+::get\+Automatan (\begin{DoxyParamCaption}{ }\end{DoxyParamCaption})\hspace{0.3cm}{\ttfamily [inline]}, {\ttfamily [protected]}}

\Hypertarget{classm0st4fa_1_1_lexical_analyzer_adee6ddc157dcbcfdc0969b8c59d2e1c0}\label{classm0st4fa_1_1_lexical_analyzer_adee6ddc157dcbcfdc0969b8c59d2e1c0} 
\index{m0st4fa::LexicalAnalyzer$<$ TokenT, TableT, InputT $>$@{m0st4fa::LexicalAnalyzer$<$ TokenT, TableT, InputT $>$}!getCol@{getCol}}
\index{getCol@{getCol}!m0st4fa::LexicalAnalyzer$<$ TokenT, TableT, InputT $>$@{m0st4fa::LexicalAnalyzer$<$ TokenT, TableT, InputT $>$}}
\doxysubsubsection{\texorpdfstring{getCol()}{getCol()}}
{\footnotesize\ttfamily template$<$typename TokenT , typename TableT  = FSMTable, typename InputT  = std\+::string\+\_\+view$>$ \\
size\+\_\+t \mbox{\hyperlink{classm0st4fa_1_1_lexical_analyzer}{m0st4fa\+::\+Lexical\+Analyzer}}$<$ TokenT, TableT, InputT $>$\+::get\+Col (\begin{DoxyParamCaption}{ }\end{DoxyParamCaption})\hspace{0.3cm}{\ttfamily [inline]}}

\Hypertarget{classm0st4fa_1_1_lexical_analyzer_a2102c8791bfff625f6dd1e1a041c58b5}\label{classm0st4fa_1_1_lexical_analyzer_a2102c8791bfff625f6dd1e1a041c58b5} 
\index{m0st4fa::LexicalAnalyzer$<$ TokenT, TableT, InputT $>$@{m0st4fa::LexicalAnalyzer$<$ TokenT, TableT, InputT $>$}!getLine@{getLine}}
\index{getLine@{getLine}!m0st4fa::LexicalAnalyzer$<$ TokenT, TableT, InputT $>$@{m0st4fa::LexicalAnalyzer$<$ TokenT, TableT, InputT $>$}}
\doxysubsubsection{\texorpdfstring{getLine()}{getLine()}}
{\footnotesize\ttfamily template$<$typename TokenT , typename TableT  = FSMTable, typename InputT  = std\+::string\+\_\+view$>$ \\
size\+\_\+t \mbox{\hyperlink{classm0st4fa_1_1_lexical_analyzer}{m0st4fa\+::\+Lexical\+Analyzer}}$<$ TokenT, TableT, InputT $>$\+::get\+Line (\begin{DoxyParamCaption}{ }\end{DoxyParamCaption})\hspace{0.3cm}{\ttfamily [inline]}}

\Hypertarget{classm0st4fa_1_1_lexical_analyzer_a360582fb5a0a0c77553dfdfcba14fcbc}\label{classm0st4fa_1_1_lexical_analyzer_a360582fb5a0a0c77553dfdfcba14fcbc} 
\index{m0st4fa::LexicalAnalyzer$<$ TokenT, TableT, InputT $>$@{m0st4fa::LexicalAnalyzer$<$ TokenT, TableT, InputT $>$}!getNextToken@{getNextToken}}
\index{getNextToken@{getNextToken}!m0st4fa::LexicalAnalyzer$<$ TokenT, TableT, InputT $>$@{m0st4fa::LexicalAnalyzer$<$ TokenT, TableT, InputT $>$}}
\doxysubsubsection{\texorpdfstring{getNextToken()}{getNextToken()}}
{\footnotesize\ttfamily template$<$typename TokenT , typename TableT , typename InputT $>$ \\
\mbox{\hyperlink{classm0st4fa_1_1_lexical_analyzer}{m0st4fa\+::\+Lexical\+Analyzer}}$<$ TokenT, TableT, InputT $>$\+::\+Result \mbox{\hyperlink{classm0st4fa_1_1_lexical_analyzer}{m0st4fa\+::\+Lexical\+Analyzer}}$<$ TokenT, TableT, InputT $>$\+::get\+Next\+Token (\begin{DoxyParamCaption}\item[{unsigned}]{flags = {\ttfamily (unsigned)\mbox{\hyperlink{namespacem0st4fa_a650a9bd65d2a3b704ebe88b2cedf33e9ab8f839029805bbb167407d29588a2df9}{LA\+\_\+\+FLAG\+::\+LAF\+\_\+\+DEFAULT}}} }\end{DoxyParamCaption})}



get the next matching token from the input, skipping all nonmatching characters in between this and the previous match. 


\begin{DoxyParams}{Parameters}
{\em flags} & to modify the behavior\+: {\ttfamily LAF\+\_\+\+DEFAULT} -\/\texorpdfstring{$>$}{>} default behavior; {\ttfamily LAF\+\_\+\+ALLOW\+\_\+\+WHITE\+\_\+\+SPACE\+\_\+\+CHARS} -\/\texorpdfstring{$>$}{>} do not skip whitespace, however include them in the token (by default, they are not included in the token); {\ttfamily LAF\+\_\+\+ALLOW\+\_\+\+NEW\+\_\+\+LINE} -\/\texorpdfstring{$>$}{>} allow only new lines, however, do not allow other whitespace characters. \\
\hline
\end{DoxyParams}
\begin{DoxyReturn}{Returns}
the next token. 
\end{DoxyReturn}
\Hypertarget{classm0st4fa_1_1_lexical_analyzer_a8fe9088959a4edcd58bd500267221cb0}\label{classm0st4fa_1_1_lexical_analyzer_a8fe9088959a4edcd58bd500267221cb0} 
\index{m0st4fa::LexicalAnalyzer$<$ TokenT, TableT, InputT $>$@{m0st4fa::LexicalAnalyzer$<$ TokenT, TableT, InputT $>$}!getPosition@{getPosition}}
\index{getPosition@{getPosition}!m0st4fa::LexicalAnalyzer$<$ TokenT, TableT, InputT $>$@{m0st4fa::LexicalAnalyzer$<$ TokenT, TableT, InputT $>$}}
\doxysubsubsection{\texorpdfstring{getPosition()}{getPosition()}}
{\footnotesize\ttfamily template$<$typename TokenT , typename TableT  = FSMTable, typename InputT  = std\+::string\+\_\+view$>$ \\
\mbox{\hyperlink{structm0st4fa_1_1_position}{Position}} \mbox{\hyperlink{classm0st4fa_1_1_lexical_analyzer}{m0st4fa\+::\+Lexical\+Analyzer}}$<$ TokenT, TableT, InputT $>$\+::get\+Position (\begin{DoxyParamCaption}{ }\end{DoxyParamCaption})\hspace{0.3cm}{\ttfamily [inline]}}

\Hypertarget{classm0st4fa_1_1_lexical_analyzer_ab0311f5dc70584a1c72b5ef08e60c434}\label{classm0st4fa_1_1_lexical_analyzer_ab0311f5dc70584a1c72b5ef08e60c434} 
\index{m0st4fa::LexicalAnalyzer$<$ TokenT, TableT, InputT $>$@{m0st4fa::LexicalAnalyzer$<$ TokenT, TableT, InputT $>$}!getSourceCode@{getSourceCode}}
\index{getSourceCode@{getSourceCode}!m0st4fa::LexicalAnalyzer$<$ TokenT, TableT, InputT $>$@{m0st4fa::LexicalAnalyzer$<$ TokenT, TableT, InputT $>$}}
\doxysubsubsection{\texorpdfstring{getSourceCode()}{getSourceCode()}}
{\footnotesize\ttfamily template$<$typename TokenT , typename TableT  = FSMTable, typename InputT  = std\+::string\+\_\+view$>$ \\
const std\+::string\+\_\+view \& \mbox{\hyperlink{classm0st4fa_1_1_lexical_analyzer}{m0st4fa\+::\+Lexical\+Analyzer}}$<$ TokenT, TableT, InputT $>$\+::get\+Source\+Code (\begin{DoxyParamCaption}{ }\end{DoxyParamCaption})\hspace{0.3cm}{\ttfamily [inline]}}

\Hypertarget{classm0st4fa_1_1_lexical_analyzer_a104e6bb82d82935f490ec847e47d32b9}\label{classm0st4fa_1_1_lexical_analyzer_a104e6bb82d82935f490ec847e47d32b9} 
\index{m0st4fa::LexicalAnalyzer$<$ TokenT, TableT, InputT $>$@{m0st4fa::LexicalAnalyzer$<$ TokenT, TableT, InputT $>$}!getTokenFactory@{getTokenFactory}}
\index{getTokenFactory@{getTokenFactory}!m0st4fa::LexicalAnalyzer$<$ TokenT, TableT, InputT $>$@{m0st4fa::LexicalAnalyzer$<$ TokenT, TableT, InputT $>$}}
\doxysubsubsection{\texorpdfstring{getTokenFactory()}{getTokenFactory()}}
{\footnotesize\ttfamily template$<$typename TokenT , typename TableT  = FSMTable, typename InputT  = std\+::string\+\_\+view$>$ \\
const \mbox{\hyperlink{namespacem0st4fa_a58965446aff3084930498d9cce4e9997}{Token\+Factory\+Type}}$<$ TokenT, InputT $>$ \mbox{\hyperlink{classm0st4fa_1_1_lexical_analyzer}{m0st4fa\+::\+Lexical\+Analyzer}}$<$ TokenT, TableT, InputT $>$\+::get\+Token\+Factory (\begin{DoxyParamCaption}{ }\end{DoxyParamCaption})\hspace{0.3cm}{\ttfamily [inline]}, {\ttfamily [protected]}}

\Hypertarget{classm0st4fa_1_1_lexical_analyzer_abcbf6d3869e434c507198d397dbf0afa}\label{classm0st4fa_1_1_lexical_analyzer_abcbf6d3869e434c507198d397dbf0afa} 
\index{m0st4fa::LexicalAnalyzer$<$ TokenT, TableT, InputT $>$@{m0st4fa::LexicalAnalyzer$<$ TokenT, TableT, InputT $>$}!operator=@{operator=}}
\index{operator=@{operator=}!m0st4fa::LexicalAnalyzer$<$ TokenT, TableT, InputT $>$@{m0st4fa::LexicalAnalyzer$<$ TokenT, TableT, InputT $>$}}
\doxysubsubsection{\texorpdfstring{operator=()}{operator=()}}
{\footnotesize\ttfamily template$<$typename TokenT , typename TableT  = FSMTable, typename InputT  = std\+::string\+\_\+view$>$ \\
\mbox{\hyperlink{classm0st4fa_1_1_lexical_analyzer}{Lexical\+Analyzer}} \& \mbox{\hyperlink{classm0st4fa_1_1_lexical_analyzer}{m0st4fa\+::\+Lexical\+Analyzer}}$<$ TokenT, TableT, InputT $>$\+::operator= (\begin{DoxyParamCaption}\item[{const \mbox{\hyperlink{classm0st4fa_1_1_lexical_analyzer}{Lexical\+Analyzer}}$<$ TokenT, TableT, InputT $>$ \&}]{rhs }\end{DoxyParamCaption})\hspace{0.3cm}{\ttfamily [inline]}}

\Hypertarget{classm0st4fa_1_1_lexical_analyzer_a649be99fb43c662f84fd9e2578e08b62}\label{classm0st4fa_1_1_lexical_analyzer_a649be99fb43c662f84fd9e2578e08b62} 
\index{m0st4fa::LexicalAnalyzer$<$ TokenT, TableT, InputT $>$@{m0st4fa::LexicalAnalyzer$<$ TokenT, TableT, InputT $>$}!peak@{peak}}
\index{peak@{peak}!m0st4fa::LexicalAnalyzer$<$ TokenT, TableT, InputT $>$@{m0st4fa::LexicalAnalyzer$<$ TokenT, TableT, InputT $>$}}
\doxysubsubsection{\texorpdfstring{peak()}{peak()}}
{\footnotesize\ttfamily template$<$typename TokenT , typename TableT , typename InputT $>$ \\
\mbox{\hyperlink{classm0st4fa_1_1_lexical_analyzer}{m0st4fa\+::\+Lexical\+Analyzer}}$<$ TokenT, TableT, InputT $>$\+::\+Result \mbox{\hyperlink{classm0st4fa_1_1_lexical_analyzer}{m0st4fa\+::\+Lexical\+Analyzer}}$<$ TokenT, TableT, InputT $>$\+::peak (\begin{DoxyParamCaption}\item[{unsigned}]{flags = {\ttfamily (unsigned)\mbox{\hyperlink{namespacem0st4fa_a650a9bd65d2a3b704ebe88b2cedf33e9ab8f839029805bbb167407d29588a2df9}{LA\+\_\+\+FLAG\+::\+LAF\+\_\+\+DEFAULT}}} }\end{DoxyParamCaption})}



peak the next token without modifying character count nor line number, except that it deals with whitespace as normal (i.\+e. may skip them, depending on the flags, and hence modify line number and character count). 

\begin{DoxyReturn}{Returns}
the next token. 
\end{DoxyReturn}


The documentation for this class was generated from the following file\+:\begin{DoxyCompactItemize}
\item 
\mbox{\hyperlink{_lexical_analyzer_8h}{Lexical\+Analyzer.\+h}}\end{DoxyCompactItemize}
